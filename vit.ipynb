{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Trnasformer ImageNet Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "if not os.path.exists('imagenet64'):\n",
    "  if not os.path.exists(checkpoints + 'imagenet64.tar'):\n",
    "    print(\"Downloading archive...\")\n",
    "    os.chdir(checkpoints)\n",
    "    !wget https://pjreddie.com/media/files/imagenet64.tar\n",
    "    os.chdir('/content/')\n",
    "  print(\"Copying to local runtime...\")\n",
    "  shutil.copy(checkpoints + 'imagenet64.tar', './imagenet64.tar')\n",
    "  print(\"Uncompressing...\")\n",
    "  !tar -xf imagenet64.tar\n",
    "print(\"Data ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_imagenet64_data():\n",
    "  # Data augmentation transformations. Not for Testing!\n",
    "  transform_train = transforms.Compose([\n",
    "    transforms.Resize(64), # Takes images smaller than 64 and enlarges them\n",
    "    transforms.RandomCrop(64, padding=4, padding_mode='edge'), # Take 64x64 crops from 72x72 padded images\n",
    "    transforms.RandomHorizontalFlip(),    # 50% of time flip image along y-axis\n",
    "    transforms.ToTensor(),\n",
    "  ])\n",
    "\n",
    "  transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "  ])\n",
    "\n",
    "  trainset = torchvision.datasets.ImageFolder(root='./imagenet64/train/', transform=transform_train)\n",
    "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "  testset = torchvision.datasets.ImageFolder(root='./imagenet64/val/', transform=transform_test)\n",
    "  testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "  return {'train': trainloader, 'test': testloader}\n",
    "\n",
    "data = get_imagenet64_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(data['train'])\n",
    "images, labels = dataiter.next()\n",
    "images = images[:8]\n",
    "print(images.size())\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(\"Labels:\" + ' '.join('%9s' % labels[j] for j in range(8)))\n",
    "\n",
    "flat = torch.flatten(images, 1)\n",
    "print(images.size())\n",
    "print(flat.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train(net, dataloader, epochs=1, start_epoch=0, lr=0.01, momentum=0.9, decay=0.0005, \n",
    "          verbose=1, print_every=10, state=None, schedule={}, checkpoint_path=None):\n",
    "  net.to(device)\n",
    "  net.train()\n",
    "  losses = []\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n",
    "\n",
    "  # Load previous training state\n",
    "  if state:\n",
    "      net.load_state_dict(state['net'])\n",
    "      optimizer.load_state_dict(state['optimizer'])\n",
    "      start_epoch = state['epoch']\n",
    "      losses = state['losses']\n",
    "\n",
    "  # Fast forward lr schedule through already trained epochs\n",
    "  for epoch in range(start_epoch):\n",
    "    if epoch in schedule:\n",
    "      print (\"Learning rate: %f\"% schedule[epoch])\n",
    "      for g in optimizer.param_groups:\n",
    "        g['lr'] = schedule[epoch]\n",
    "\n",
    "  for epoch in range(start_epoch, epochs):\n",
    "    sum_loss = 0.0\n",
    "\n",
    "    # Update learning rate when scheduled\n",
    "    if epoch in schedule:\n",
    "      print (\"Learning rate: %f\"% schedule[epoch])\n",
    "      for g in optimizer.param_groups:\n",
    "        g['lr'] = schedule[epoch]\n",
    "\n",
    "    for i, batch in enumerate(dataloader, 0):\n",
    "        inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  # autograd magic, computes all the partial derivatives\n",
    "        optimizer.step() # takes a step in gradient direction\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        sum_loss += loss.item()\n",
    "        \n",
    "        if i % print_every == print_every-1:    # print every 10 mini-batches\n",
    "            if verbose:\n",
    "              print('[%d, %5d] loss: %.3f' % (epoch, i + 1, sum_loss / print_every))\n",
    "            sum_loss = 0.0\n",
    "    if checkpoint_path:\n",
    "      state = {'epoch': epoch+1, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': losses}\n",
    "      torch.save(state, checkpoint_path + 'checkpoint-%d.pkl'%(epoch+1))\n",
    "  return losses\n",
    "\n",
    "def accuracy(net, dataloader):\n",
    "  net.to(device)\n",
    "  net.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "      for batch in dataloader:\n",
    "          images, labels = batch[0].to(device), batch[1].to(device)\n",
    "          outputs = net(images)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "  return correct/total\n",
    "\n",
    "def smooth(x, size):\n",
    "  return np.convolve(x, np.ones(size)/size, mode='valid')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
